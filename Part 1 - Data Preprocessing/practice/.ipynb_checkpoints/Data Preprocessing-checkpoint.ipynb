{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['France', 44.0, 72000.0],\n",
       "       ['Spain', 27.0, 48000.0],\n",
       "       ['Germany', 30.0, 54000.0],\n",
       "       ['Spain', 38.0, 61000.0],\n",
       "       ['Germany', 40.0, nan],\n",
       "       ['France', 35.0, 58000.0],\n",
       "       ['Spain', nan, 52000.0],\n",
       "       ['France', 48.0, 79000.0],\n",
       "       ['Germany', 50.0, 83000.0],\n",
       "       ['France', 37.0, 67000.0]], dtype=object)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds = pd.read_csv('../Data.csv')\n",
    "#iloc[rows,cols]\n",
    "X = ds.iloc[:,:-1].values\n",
    "y = ds.iloc[:,3].values\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['France', 44.0, 72000.0],\n",
       "       ['Spain', 27.0, 48000.0],\n",
       "       ['Germany', 30.0, 54000.0],\n",
       "       ['Spain', 38.0, 61000.0],\n",
       "       ['Germany', 40.0, 48000.0],\n",
       "       ['France', 35.0, 58000.0],\n",
       "       ['Spain', 27.0, 52000.0],\n",
       "       ['France', 48.0, 79000.0],\n",
       "       ['Germany', 50.0, 83000.0],\n",
       "       ['France', 37.0, 67000.0]], dtype=object)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import Imputer, LabelEncoder, OneHotEncoder\n",
    "\n",
    "#strategy can be most_frequent, mean, median\n",
    "imputer = Imputer(strategy='most_frequent',axis=0)\n",
    "#select which drop want to be replace with mean\n",
    "imputer = imputer.fit(X[:, 1:3])\n",
    "#transform column and replace the existing column\n",
    "X[:, 1:3] = imputer.transform(X[:, 1:3])\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert to categorical value not ordinal value\n",
    "X[:,0] = LabelEncoder().fit_transform(X[:,0])\n",
    "y[:,] = LabelEncoder().fit_transform(y[:,])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.0e+00, 0.0e+00, 0.0e+00, 4.4e+01, 7.2e+04],\n",
       "       [0.0e+00, 0.0e+00, 1.0e+00, 2.7e+01, 4.8e+04],\n",
       "       [0.0e+00, 1.0e+00, 0.0e+00, 3.0e+01, 5.4e+04],\n",
       "       [0.0e+00, 0.0e+00, 1.0e+00, 3.8e+01, 6.1e+04],\n",
       "       [0.0e+00, 1.0e+00, 0.0e+00, 4.0e+01, 4.8e+04],\n",
       "       [1.0e+00, 0.0e+00, 0.0e+00, 3.5e+01, 5.8e+04],\n",
       "       [0.0e+00, 0.0e+00, 1.0e+00, 2.7e+01, 5.2e+04],\n",
       "       [1.0e+00, 0.0e+00, 0.0e+00, 4.8e+01, 7.9e+04],\n",
       "       [0.0e+00, 1.0e+00, 0.0e+00, 5.0e+01, 8.3e+04],\n",
       "       [1.0e+00, 0.0e+00, 0.0e+00, 3.7e+01, 6.7e+04]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#need to convert the label to dummy variables\n",
    "onehotencoder = OneHotEncoder(categorical_features=[0])\n",
    "X = onehotencoder.fit_transform(X).toarray()\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, 0, 1, 1, 0, 1, 0, 1], dtype=object)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#only yes/ no\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((8, 5), (2, 5), (8,), (2,))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train test split example\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[-1.        ,  2.64575131, -0.77459667,  0.4330127 , -1.1851228 ],\n",
       "        [ 1.        , -0.37796447, -0.77459667,  0.        ,  0.59842834],\n",
       "        [-1.        , -0.37796447,  1.29099445, -1.44337567, -1.1851228 ],\n",
       "        [-1.        , -0.37796447,  1.29099445, -1.44337567, -0.80963835],\n",
       "        [ 1.        , -0.37796447, -0.77459667,  1.58771324,  1.72488169],\n",
       "        [-1.        , -0.37796447,  1.29099445,  0.14433757,  0.03520167],\n",
       "        [ 1.        , -0.37796447, -0.77459667,  1.01036297,  1.0677839 ],\n",
       "        [ 1.        , -0.37796447, -0.77459667, -0.28867513, -0.24641167]]),\n",
       " array([[-1.        ,  2.64575131, -0.77459667, -1.01036297, -0.62189612],\n",
       "        [-1.        ,  2.64575131, -0.77459667,  1.87638837,  2.10036614]]))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#feature scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "#standardisation\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)\n",
    "\n",
    "'''do we need to apply feature scaling to dummy variables ? depends on the context - \n",
    "if you don't apply to feature scaling it won't break your models \n",
    "you don't need to apply feature scaling on y_train, y_test\n",
    "'''\n",
    "X_train, X_test"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow-gpu]",
   "language": "python",
   "name": "conda-env-tensorflow-gpu-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
